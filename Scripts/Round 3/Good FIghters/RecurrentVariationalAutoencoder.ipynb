{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense, LSTM, RepeatVector, TimeDistributed, Lambda\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from sklearn.preprocessing import normalize\n",
    "from keras import backend as K\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Datasets.zip',\n",
       " '.DS_Store',\n",
       " 'Inmate_Admissions Data Dictionary.xlsx',\n",
       " 'Datasets',\n",
       " 'ACS Artificial Intelligence Starter Guide.pdf',\n",
       " '16-0026_DATA61_REPORT_TomorrowsDigiallyEnabledWorkforce_WEB_160128.pdf',\n",
       " 'Offence Charge Code Lookup.xlsx',\n",
       " 'Inmate_Admissions.csv',\n",
       " 'DirectedIdeation_20190708123418.ipynb',\n",
       " 'ACS_Data-Sharing-Frameworks_FINAL_FA_SINGLE_LR.pdf',\n",
       " 'directed',\n",
       " 'Inmate_Admissions_sample.csv',\n",
       " 'AFR-jobs-of-the-future-5JUN2018.pdf',\n",
       " 'RecurrentVariationalAutoencoder.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'ACS Data Sharing Taskforce - Directed Ideation Report - 26th March 2019_v1.1.pdf',\n",
       " 'ACS Directed Ideation - Information Evening 1st July 2019_v1_3.pptx']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Inmate_Admissions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301747, 7)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INMATEID               int64\n",
       "ADMITTED_DT           object\n",
       "DISCHARGED_DT         object\n",
       "RACE                  object\n",
       "GENDER                object\n",
       "INMATE_STATUS_CODE    object\n",
       "TOP_CHARGE            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ADMITTED_DT = data.ADMITTED_DT.astype('datetime64[ns]')\n",
    "data.DISCHARGED_DT = data.DISCHARGED_DT.astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_vals(myval, mydict):\n",
    "    try:\n",
    "        return mydict[myval]\n",
    "    except KeyError:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def create_sparse_dict(df):\n",
    "    labels = df.value_counts().sort_values()\n",
    "    lookup_dict = {}\n",
    "    c = 1 # starting from 1 because we will 0-pad\n",
    "    for i, v in labels.items():\n",
    "        lookup_dict[i] = c\n",
    "        c += 1\n",
    "    df = pd.DataFrame(df.apply(lookup_vals, args=(lookup_dict,)))\n",
    "    return df, lookup_dict\n",
    "\n",
    "\n",
    "def date_to_int(dt):\n",
    "    return (dt - datetime.datetime(1970,1,1)).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.RACE, race_dict = create_sparse_dict(data.RACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.GENDER, gender_dict = create_sparse_dict(data.GENDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.INMATE_STATUS_CODE, status_dict = create_sparse_dict(data.INMATE_STATUS_CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.TOP_CHARGE, charge_dict = create_sparse_dict(data.TOP_CHARGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ADMITTED_DT = data.ADMITTED_DT.apply(date_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.DISCHARGED_DT = data.DISCHARGED_DT.apply(date_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INMATEID                int64\n",
       "ADMITTED_DT           float64\n",
       "DISCHARGED_DT         float64\n",
       "RACE                    int64\n",
       "GENDER                  int64\n",
       "INMATE_STATUS_CODE      int64\n",
       "TOP_CHARGE              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INMATEID</th>\n",
       "      <th>ADMITTED_DT</th>\n",
       "      <th>DISCHARGED_DT</th>\n",
       "      <th>RACE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>INMATE_STATUS_CODE</th>\n",
       "      <th>TOP_CHARGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.017470e+05</td>\n",
       "      <td>3.017470e+05</td>\n",
       "      <td>3.017470e+05</td>\n",
       "      <td>301747.000000</td>\n",
       "      <td>301747.000000</td>\n",
       "      <td>301747.000000</td>\n",
       "      <td>301747.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.273267e+07</td>\n",
       "      <td>1.465263e+09</td>\n",
       "      <td>1.271692e+09</td>\n",
       "      <td>2.530547</td>\n",
       "      <td>2.902551</td>\n",
       "      <td>7.411106</td>\n",
       "      <td>569.159120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.537441e+06</td>\n",
       "      <td>4.812781e+07</td>\n",
       "      <td>4.903313e+08</td>\n",
       "      <td>0.534101</td>\n",
       "      <td>0.304813</td>\n",
       "      <td>1.188958</td>\n",
       "      <td>32.535329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>1.388561e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.073410e+05</td>\n",
       "      <td>1.423623e+09</td>\n",
       "      <td>1.407960e+09</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>577.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.007140e+07</td>\n",
       "      <td>1.462123e+09</td>\n",
       "      <td>1.446598e+09</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>579.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.015021e+07</td>\n",
       "      <td>1.504281e+09</td>\n",
       "      <td>1.487789e+09</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>579.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.020468e+07</td>\n",
       "      <td>1.559347e+09</td>\n",
       "      <td>1.559376e+09</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>579.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           INMATEID   ADMITTED_DT  DISCHARGED_DT           RACE  \\\n",
       "count  3.017470e+05  3.017470e+05   3.017470e+05  301747.000000   \n",
       "mean   1.273267e+07  1.465263e+09   1.271692e+09       2.530547   \n",
       "std    9.537441e+06  4.812781e+07   4.903313e+08       0.534101   \n",
       "min    1.700000e+01  1.388561e+09   0.000000e+00       1.000000   \n",
       "25%    1.073410e+05  1.423623e+09   1.407960e+09       2.000000   \n",
       "50%    2.007140e+07  1.462123e+09   1.446598e+09       3.000000   \n",
       "75%    2.015021e+07  1.504281e+09   1.487789e+09       3.000000   \n",
       "max    2.020468e+07  1.559347e+09   1.559376e+09       3.000000   \n",
       "\n",
       "              GENDER  INMATE_STATUS_CODE     TOP_CHARGE  \n",
       "count  301747.000000       301747.000000  301747.000000  \n",
       "mean        2.902551            7.411106     569.159120  \n",
       "std         0.304813            1.188958      32.535329  \n",
       "min         1.000000            1.000000       1.000000  \n",
       "25%         3.000000            7.000000     577.000000  \n",
       "50%         3.000000            8.000000     579.000000  \n",
       "75%         3.000000            8.000000     579.000000  \n",
       "max         3.000000            8.000000     579.000000  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('Inmate_Admissions_Numeric.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn inmate rows into trajectories\n",
    "inmates = []\n",
    "for i_id in data.INMATEID.unique():\n",
    "    inmates.append(data[data.INMATEID == i_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_len = max([len(x) for x in inmates])\n",
    "feature_list = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_inmates = []\n",
    "for inmate in inmates:\n",
    "    padding = pd.DataFrame(0, index=np.arange(padded_len - len(inmate)), columns=feature_list)\n",
    "    padded_inmates.append(pd.concat([inmate, padding]).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = train_test_split(padded_inmates, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_train = np.array(x_train)\n",
    "final_data_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_train = final_data_train[:,:,1:]\n",
    "final_data_test = final_data_test[:,:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74463, 43, 6)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_train = final_data_train / np.linalg.norm(final_data_train)\n",
    "final_data_test = final_data_test / np.linalg.norm(final_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 59570 samples, validate on 14893 samples\n",
      "Epoch 1/50\n",
      "59570/59570 [==============================] - 29s 489us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 2/50\n",
      "59570/59570 [==============================] - 27s 457us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 3/50\n",
      "59570/59570 [==============================] - 28s 469us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 4/50\n",
      "59570/59570 [==============================] - 30s 503us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 5/50\n",
      "59570/59570 [==============================] - 30s 502us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 6/50\n",
      "59570/59570 [==============================] - 30s 509us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 7/50\n",
      "59570/59570 [==============================] - 30s 510us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 8/50\n",
      "59570/59570 [==============================] - 30s 511us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 9/50\n",
      "59570/59570 [==============================] - 31s 515us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "59570/59570 [==============================] - 30s 505us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 11/50\n",
      "59570/59570 [==============================] - 31s 513us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 12/50\n",
      "59570/59570 [==============================] - 31s 522us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 13/50\n",
      "59570/59570 [==============================] - 32s 533us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 14/50\n",
      "59570/59570 [==============================] - 32s 539us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 15/50\n",
      "59570/59570 [==============================] - 30s 498us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 16/50\n",
      "59570/59570 [==============================] - 30s 502us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 17/50\n",
      "59570/59570 [==============================] - 30s 509us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "59570/59570 [==============================] - 32s 540us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 19/50\n",
      "59570/59570 [==============================] - 31s 515us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 20/50\n",
      "59570/59570 [==============================] - 31s 522us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 21/50\n",
      "59570/59570 [==============================] - 32s 545us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 22/50\n",
      "59570/59570 [==============================] - 30s 506us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 23/50\n",
      "59570/59570 [==============================] - 31s 523us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 24/50\n",
      "59570/59570 [==============================] - 33s 553us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 25/50\n",
      "59570/59570 [==============================] - 31s 521us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 26/50\n",
      "59570/59570 [==============================] - 31s 513us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 27/50\n",
      "59570/59570 [==============================] - 31s 520us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 28/50\n",
      "59570/59570 [==============================] - 31s 516us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 29/50\n",
      "59570/59570 [==============================] - 32s 530us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 30/50\n",
      "59570/59570 [==============================] - 31s 525us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 31/50\n",
      "59570/59570 [==============================] - 34s 563us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 32/50\n",
      "59570/59570 [==============================] - 31s 518us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 33/50\n",
      "59570/59570 [==============================] - 30s 509us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 34/50\n",
      "59570/59570 [==============================] - 30s 512us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 35/50\n",
      "59570/59570 [==============================] - 30s 497us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 36/50\n",
      "59570/59570 [==============================] - 31s 513us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 37/50\n",
      "59570/59570 [==============================] - 31s 512us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 38/50\n",
      "59570/59570 [==============================] - 31s 515us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 39/50\n",
      "59570/59570 [==============================] - 31s 515us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 40/50\n",
      "59570/59570 [==============================] - 33s 550us/step - loss: 0.0010 - val_loss: 9.9896e-04\n",
      "Epoch 41/50\n",
      "59570/59570 [==============================] - 32s 536us/step - loss: 0.0010 - val_loss: 9.9704e-04\n",
      "Epoch 42/50\n",
      "59570/59570 [==============================] - 32s 531us/step - loss: 0.0010 - val_loss: 9.9518e-04\n",
      "Epoch 43/50\n",
      "59570/59570 [==============================] - 31s 513us/step - loss: 9.9996e-04 - val_loss: 9.9336e-04\n",
      "Epoch 44/50\n",
      "59570/59570 [==============================] - 31s 526us/step - loss: 9.9814e-04 - val_loss: 9.9158e-04\n",
      "Epoch 45/50\n",
      "59570/59570 [==============================] - 29s 495us/step - loss: 9.9637e-04 - val_loss: 9.8984e-04\n",
      "Epoch 46/50\n",
      "59570/59570 [==============================] - 30s 510us/step - loss: 9.9464e-04 - val_loss: 9.8814e-04\n",
      "Epoch 47/50\n",
      "59570/59570 [==============================] - 31s 518us/step - loss: 9.9295e-04 - val_loss: 9.8647e-04\n",
      "Epoch 48/50\n",
      "59570/59570 [==============================] - 30s 497us/step - loss: 9.9130e-04 - val_loss: 9.8484e-04\n",
      "Epoch 49/50\n",
      "59570/59570 [==============================] - 30s 504us/step - loss: 9.8968e-04 - val_loss: 9.8325e-04\n",
      "Epoch 50/50\n",
      "59570/59570 [==============================] - 30s 500us/step - loss: 9.8809e-04 - val_loss: 9.8169e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1caa23cf60>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timesteps = 43\n",
    "input_dim = 6\n",
    "input_shape = (timesteps,input_dim)\n",
    "latent_dim = 3\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(latent_dim, activation='tanh', input_shape=input_shape))\n",
    "model.add(RepeatVector(timesteps))\n",
    "model.add(LSTM(latent_dim, activation='tanh', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(input_dim)))\n",
    "opt = RMSprop(lr=1e-8)\n",
    "model.compile(optimizer=opt, loss='kullback_leibler_divergence')\n",
    "\n",
    "# fit model\n",
    "model.fit(final_data, final_data, \n",
    "          epochs=epochs, \n",
    "          verbose=1,\n",
    "          shuffle=True,\n",
    "          batch_size=batch_size,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 258)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_74 (Dense)                (None, 10)           2590        encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            22          dense_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            22          dense_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,634\n",
      "Trainable params: 2,634\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "--------------------------\n",
      "Decoder\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 258)               2838      \n",
      "=================================================================\n",
      "Total params: 2,868\n",
      "Trainable params: 2,868\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "max_traj_len = final_data_train.shape[1] # 43\n",
    "original_dim = final_data_train.shape[2] * max_traj_len # 6\n",
    "input_shape = (original_dim,)\n",
    "x_train = np.reshape(final_data_train, [-1, original_dim])\n",
    "x_test = np.reshape(final_data_test, [-1, original_dim])\n",
    "intermediate_dim = 10\n",
    "latent_dim = 2\n",
    "epochs = 50\n",
    "\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "# use reparameterization trick to push the sampling out as input\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "# # instantiate encoder model\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "print('Encoder')\n",
    "encoder.summary()\n",
    "\n",
    "# # build decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = Dense(original_dim, activation='sigmoid')(x)\n",
    "\n",
    "# # instantiate decoder model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "print('--------------------------')\n",
    "print('Decoder')\n",
    "decoder.summary()\n",
    "\n",
    "# # instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae_mlp')\n",
    "\n",
    "\n",
    "models = (encoder, decoder)\n",
    "data = (x_test, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 258)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 2), (None, 2), (N 2634      \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 258)               2868      \n",
      "=================================================================\n",
      "Total params: 5,502\n",
      "Trainable params: 5,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 74463 samples, validate on 74463 samples\n",
      "Epoch 1/50\n",
      "74463/74463 [==============================] - 5s 61us/step - loss: 16.6894 - val_loss: 2.0553\n",
      "Epoch 2/50\n",
      "74463/74463 [==============================] - 2s 26us/step - loss: 1.4048 - val_loss: 0.9815\n",
      "Epoch 3/50\n",
      "74463/74463 [==============================] - 2s 26us/step - loss: 0.6892 - val_loss: 0.4283\n",
      "Epoch 4/50\n",
      "74463/74463 [==============================] - 2s 27us/step - loss: 0.2487 - val_loss: 0.1210\n",
      "Epoch 5/50\n",
      "74463/74463 [==============================] - 2s 25us/step - loss: 0.0697 - val_loss: 0.0371\n",
      "Epoch 6/50\n",
      "74463/74463 [==============================] - 2s 25us/step - loss: 0.0245 - val_loss: 0.0163\n",
      "Epoch 7/50\n",
      "74463/74463 [==============================] - 2s 26us/step - loss: 0.0123 - val_loss: 0.0092\n",
      "Epoch 8/50\n",
      "74463/74463 [==============================] - 2s 27us/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 9/50\n",
      "74463/74463 [==============================] - 2s 29us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 10/50\n",
      "74463/74463 [==============================] - 2s 27us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 11/50\n",
      "74463/74463 [==============================] - 2s 27us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 12/50\n",
      "74463/74463 [==============================] - 2s 26us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 13/50\n",
      "74463/74463 [==============================] - 2s 27us/step - loss: 0.0011 - val_loss: 9.2637e-04\n",
      "Epoch 14/50\n",
      "74463/74463 [==============================] - 2s 26us/step - loss: 7.8661e-04 - val_loss: 6.6547e-04\n",
      "Epoch 15/50\n",
      "74463/74463 [==============================] - 2s 25us/step - loss: 5.6541e-04 - val_loss: 4.7983e-04\n",
      "Epoch 16/50\n",
      "74463/74463 [==============================] - 2s 26us/step - loss: 4.0919e-04 - val_loss: 3.4688e-04\n",
      "Epoch 17/50\n",
      "74463/74463 [==============================] - 2s 26us/step - loss: 2.9661e-04 - val_loss: 2.5189e-04\n",
      "Epoch 18/50\n",
      "74463/74463 [==============================] - 2s 29us/step - loss: 2.1696e-04 - val_loss: 1.8439e-04\n",
      "Epoch 19/50\n",
      "74463/74463 [==============================] - 2s 29us/step - loss: 1.5950e-04 - val_loss: 1.3525e-04\n",
      "Epoch 20/50\n",
      "74463/74463 [==============================] - 2s 25us/step - loss: 1.1733e-04 - val_loss: 1.0100e-04\n",
      "Epoch 21/50\n",
      "74463/74463 [==============================] - 2s 25us/step - loss: 8.7257e-05 - val_loss: 7.4661e-05\n",
      "Epoch 22/50\n",
      "74463/74463 [==============================] - 2s 26us/step - loss: 6.5357e-05 - val_loss: 5.6232e-05\n",
      "Epoch 23/50\n",
      "74463/74463 [==============================] - 2s 27us/step - loss: 4.9452e-05 - val_loss: 4.3034e-05\n",
      "Epoch 24/50\n",
      "74463/74463 [==============================] - 2s 33us/step - loss: 3.7924e-05 - val_loss: 3.3226e-05\n",
      "Epoch 25/50\n",
      "74463/74463 [==============================] - 2s 32us/step - loss: 2.9471e-05 - val_loss: 2.6202e-05\n",
      "Epoch 26/50\n",
      "74463/74463 [==============================] - 2s 26us/step - loss: 2.3390e-05 - val_loss: 2.0972e-05\n",
      "Epoch 27/50\n",
      "74463/74463 [==============================] - 2s 28us/step - loss: 1.8981e-05 - val_loss: 1.7165e-05\n",
      "Epoch 28/50\n",
      "74463/74463 [==============================] - 2s 31us/step - loss: 1.5771e-05 - val_loss: 1.4326e-05\n",
      "Epoch 29/50\n",
      "74463/74463 [==============================] - 2s 25us/step - loss: 1.3314e-05 - val_loss: 1.2312e-05\n",
      "Epoch 30/50\n",
      "74463/74463 [==============================] - 2s 26us/step - loss: 1.1549e-05 - val_loss: 1.0802e-05\n",
      "Epoch 31/50\n",
      "74463/74463 [==============================] - 2s 25us/step - loss: 1.0257e-05 - val_loss: 9.7109e-06\n",
      "Epoch 32/50\n",
      "74463/74463 [==============================] - 2s 26us/step - loss: 9.2899e-06 - val_loss: 8.8593e-06\n",
      "Epoch 33/50\n",
      "74463/74463 [==============================] - 2s 25us/step - loss: 8.5457e-06 - val_loss: 8.2205e-06\n",
      "Epoch 34/50\n",
      "74463/74463 [==============================] - 2s 24us/step - loss: 7.9990e-06 - val_loss: 7.7202e-06\n",
      "Epoch 35/50\n",
      "74463/74463 [==============================] - 2s 26us/step - loss: 7.5511e-06 - val_loss: 7.3059e-06\n",
      "Epoch 36/50\n",
      "74463/74463 [==============================] - 2s 25us/step - loss: 7.1839e-06 - val_loss: 6.9836e-06\n",
      "Epoch 37/50\n",
      "74463/74463 [==============================] - 2s 25us/step - loss: 6.8878e-06 - val_loss: 6.7114e-06\n",
      "Epoch 38/50\n",
      "74463/74463 [==============================] - 2s 24us/step - loss: 6.6408e-06 - val_loss: 6.4988e-06\n",
      "Epoch 39/50\n",
      "74463/74463 [==============================] - 2s 24us/step - loss: 6.4436e-06 - val_loss: 6.3239e-06\n",
      "Epoch 40/50\n",
      "74463/74463 [==============================] - 2s 25us/step - loss: 6.2951e-06 - val_loss: 6.1986e-06\n",
      "Epoch 41/50\n",
      "74463/74463 [==============================] - 2s 24us/step - loss: 6.1989e-06 - val_loss: 6.1099e-06\n",
      "Epoch 42/50\n",
      "74463/74463 [==============================] - 2s 24us/step - loss: 6.1180e-06 - val_loss: 6.0496e-06\n",
      "Epoch 43/50\n",
      "74463/74463 [==============================] - 2s 24us/step - loss: 6.0583e-06 - val_loss: 5.9878e-06\n",
      "Epoch 44/50\n",
      "74463/74463 [==============================] - 2s 27us/step - loss: 6.0017e-06 - val_loss: 5.9429e-06\n",
      "Epoch 45/50\n",
      "74463/74463 [==============================] - 2s 24us/step - loss: 5.9723e-06 - val_loss: 5.9041e-06\n",
      "Epoch 46/50\n",
      "74463/74463 [==============================] - 2s 26us/step - loss: 5.9340e-06 - val_loss: 5.8805e-06\n",
      "Epoch 47/50\n",
      "74463/74463 [==============================] - 2s 25us/step - loss: 5.9053e-06 - val_loss: 5.8537e-06\n",
      "Epoch 48/50\n",
      "74463/74463 [==============================] - 2s 25us/step - loss: 5.8887e-06 - val_loss: 5.8373e-06\n",
      "Epoch 49/50\n",
      "74463/74463 [==============================] - 2s 25us/step - loss: 5.8717e-06 - val_loss: 5.8221e-06\n",
      "Epoch 50/50\n",
      "74463/74463 [==============================] - 2s 25us/step - loss: 5.8598e-06 - val_loss: 5.8064e-06\n"
     ]
    }
   ],
   "source": [
    "reconstruction_loss = mse(inputs, outputs)\n",
    "reconstruction_loss *= original_dim\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "vae.summary()\n",
    "\n",
    "vae.fit(x_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, None), callbacks=[TensorBoard(log_dir='/tmp/autoencoder2')]) \n",
    "vae.save_weights('vae_traj.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot_results(models, data, batch_size=batch_size, model_name=\"vae_mlp\")\n",
    "model_name = 'vae_mlp'\n",
    "x_test, y_test = data\n",
    "os.makedirs(model_name, exist_ok=True)\n",
    "\n",
    "filename = os.path.join(model_name, \"vae_mean.png\")\n",
    "# display a 2D plot of the digit classes in the latent space\n",
    "z_mean, _, _ = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.xlim(min(z_mean[:, 0]), max(z_mean[:, 0]))\n",
    "plt.ylim(min(z_mean[:, 1]), max(z_mean[:, 1]))\n",
    "plt.scatter(z_mean[:, 0], z_mean[:, 1])#, c=y_test)\n",
    "#plt.colorbar()\n",
    "plt.xlabel(\"z[0]\")\n",
    "plt.ylabel(\"z[1]\")\n",
    "# plt.savefig(filename)\n",
    "plt.show()\n",
    "\n",
    "# filename = os.path.join(model_name, \"digits_over_latent.png\")\n",
    "# # display a 30x30 2D manifold of digits\n",
    "# n = 30\n",
    "# digit_size = 28\n",
    "# figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# # linearly spaced coordinates corresponding to the 2D plot\n",
    "# # of digit classes in the latent space\n",
    "# grid_x = np.linspace(-4, 4, n)\n",
    "# grid_y = np.linspace(-4, 4, n)[::-1]\n",
    "\n",
    "# for i, yi in enumerate(grid_y):\n",
    "#     for j, xi in enumerate(grid_x):\n",
    "#         z_sample = np.array([[xi, yi]])\n",
    "#         x_decoded = decoder.predict(z_sample)\n",
    "#         digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "#         figure[i * digit_size: (i + 1) * digit_size,\n",
    "#                j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# start_range = digit_size // 2\n",
    "# end_range = n * digit_size + start_range + 1\n",
    "# pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "# sample_range_x = np.round(grid_x, 1)\n",
    "# sample_range_y = np.round(grid_y, 1)\n",
    "# plt.xticks(pixel_range, sample_range_x)\n",
    "# plt.yticks(pixel_range, sample_range_y)\n",
    "# plt.xlabel(\"z[0]\")\n",
    "# plt.ylabel(\"z[1]\")\n",
    "# plt.imshow(figure, cmap='Greys_r')\n",
    "# plt.savefig(filename)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HACKY HACKY HACKY WE WERE IN A HURRY AT THIS POINT OK???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_four = [(np.Inf,0), (np.Inf,0), (np.Inf,0), (np.Inf,0)]\n",
    "for i in range(len(z_mean)):\n",
    "    if z_mean[i][0] < lowest_four[0][0]:\n",
    "        lowest_four[0] = (z_mean[i][0],i) \n",
    "    elif z_mean[i][0] < lowest_four[1][0]:\n",
    "        lowest_four[1] = (z_mean[i][0],i) \n",
    "    elif z_mean[i][0] < lowest_four[2][0]:\n",
    "        lowest_four[2] = (z_mean[i][0],i) \n",
    "    elif z_mean[i][0] < lowest_four[3][0]:\n",
    "        lowest_four[3] = (z_mean[i][0],i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.00042025372, 68569),\n",
       " (-0.00024250522, 68834),\n",
       " (-0.000176806, 70525),\n",
       " (-0.00014745444, 71745)]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowest_four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.95477983e-03, 1.95512009e-03, 3.86109172e-12, 3.86109172e-12,\n",
       "       9.00921402e-12, 7.43903672e-10, 1.95907619e-03, 1.95923610e-03,\n",
       "       3.86109172e-12, 3.86109172e-12, 9.00921402e-12, 7.43903672e-10,\n",
       "       1.95997823e-03, 1.96056593e-03, 3.86109172e-12, 3.86109172e-12,\n",
       "       9.00921402e-12, 7.43903672e-10, 1.96890405e-03, 0.00000000e+00,\n",
       "       3.86109172e-12, 3.86109172e-12, 9.00921402e-12, 7.43903672e-10,\n",
       "       1.97184376e-03, 1.97266373e-03, 3.86109172e-12, 3.86109172e-12,\n",
       "       1.02962446e-11, 7.45190703e-10, 1.98478156e-03, 1.98510626e-03,\n",
       "       3.86109172e-12, 3.86109172e-12, 1.02962446e-11, 7.45190703e-10,\n",
       "       1.84129155e-03, 1.84181373e-03, 3.86109172e-12, 3.86109172e-12,\n",
       "       9.00921402e-12, 7.43903672e-10, 1.87044828e-03, 1.87173858e-03,\n",
       "       3.86109172e-12, 3.86109172e-12, 9.00921402e-12, 7.43903672e-10,\n",
       "       1.85086875e-03, 1.85115525e-03, 3.86109172e-12, 3.86109172e-12,\n",
       "       9.00921402e-12, 7.43903672e-10, 1.84429546e-03, 1.84559536e-03,\n",
       "       3.86109172e-12, 3.86109172e-12, 9.00921402e-12, 7.43903672e-10,\n",
       "       1.83573627e-03, 1.83625160e-03, 3.86109172e-12, 3.86109172e-12,\n",
       "       9.00921402e-12, 7.45190703e-10, 1.87982532e-03, 1.88039708e-03,\n",
       "       3.86109172e-12, 3.86109172e-12, 9.00921402e-12, 7.43903672e-10,\n",
       "       1.86820667e-03, 1.86985090e-03, 3.86109172e-12, 3.86109172e-12,\n",
       "       9.00921402e-12, 7.43903672e-10, 1.94696006e-03, 1.94721937e-03,\n",
       "       3.86109172e-12, 3.86109172e-12, 9.00921402e-12, 7.43903672e-10,\n",
       "       1.88488354e-03, 1.88540862e-03, 3.86109172e-12, 3.86109172e-12,\n",
       "       9.00921402e-12, 7.43903672e-10, 1.85358110e-03, 1.85419463e-03,\n",
       "       3.86109172e-12, 3.86109172e-12, 1.02962446e-11, 7.45190703e-10,\n",
       "       1.87498864e-03, 1.87807741e-03, 3.86109172e-12, 3.86109172e-12,\n",
       "       9.00921402e-12, 7.43903672e-10, 1.89900445e-03, 1.89942330e-03,\n",
       "       3.86109172e-12, 3.86109172e-12, 9.00921402e-12, 7.45190703e-10,\n",
       "       1.84210783e-03, 1.84303607e-03, 3.86109172e-12, 3.86109172e-12,\n",
       "       9.00921402e-12, 7.43903672e-10, 1.86599504e-03, 1.86727423e-03,\n",
       "       3.86109172e-12, 3.86109172e-12, 9.00921402e-12, 7.43903672e-10,\n",
       "       1.94271062e-03, 1.94289927e-03, 3.86109172e-12, 3.86109172e-12,\n",
       "       9.00921402e-12, 7.43903672e-10, 1.93127399e-03, 1.93255271e-03,\n",
       "       3.86109172e-12, 3.86109172e-12, 9.00921402e-12, 7.43903672e-10,\n",
       "       1.88558716e-03, 1.88734828e-03, 3.86109172e-12, 3.86109172e-12,\n",
       "       1.02962446e-11, 7.45190703e-10, 1.86524024e-03, 1.86581791e-03,\n",
       "       3.86109172e-12, 3.86109172e-12, 9.00921402e-12, 6.92422449e-10,\n",
       "       1.87878926e-03, 1.87878956e-03, 3.86109172e-12, 3.86109172e-12,\n",
       "       1.02962446e-11, 7.43903672e-10, 1.84678331e-03, 1.84703732e-03,\n",
       "       3.86109172e-12, 3.86109172e-12, 9.00921402e-12, 7.43903672e-10,\n",
       "       1.94549541e-03, 1.94577764e-03, 3.86109172e-12, 3.86109172e-12,\n",
       "       9.00921402e-12, 7.43903672e-10, 1.89729633e-03, 1.89865858e-03,\n",
       "       3.86109172e-12, 3.86109172e-12, 9.00921402e-12, 7.43903672e-10,\n",
       "       1.82885737e-03, 1.82924811e-03, 3.86109172e-12, 3.86109172e-12,\n",
       "       9.00921402e-12, 7.43903672e-10, 1.89960368e-03, 1.90015691e-03,\n",
       "       3.86109172e-12, 3.86109172e-12, 1.02962446e-11, 7.45190703e-10,\n",
       "       1.86057723e-03, 1.86081517e-03, 3.86109172e-12, 3.86109172e-12,\n",
       "       1.02962446e-11, 7.45190703e-10, 1.83944655e-03, 1.83992218e-03,\n",
       "       3.86109172e-12, 3.86109172e-12, 9.00921402e-12, 7.43903672e-10,\n",
       "       1.91837553e-03, 1.91931326e-03, 3.86109172e-12, 3.86109172e-12,\n",
       "       9.00921402e-12, 7.43903672e-10, 1.98710048e-03, 1.98769736e-03,\n",
       "       3.86109172e-12, 3.86109172e-12, 9.00921402e-12, 7.43903672e-10,\n",
       "       1.98887927e-03, 1.98892681e-03, 3.86109172e-12, 3.86109172e-12,\n",
       "       9.00921402e-12, 6.44802318e-10, 1.99167222e-03, 1.99204511e-03,\n",
       "       3.86109172e-12, 3.86109172e-12, 9.00921402e-12, 7.43903672e-10,\n",
       "       1.99297494e-03, 1.99348243e-03, 3.86109172e-12, 3.86109172e-12,\n",
       "       9.00921402e-12, 7.43903672e-10, 1.99369785e-03, 1.99471173e-03,\n",
       "       3.86109172e-12, 3.86109172e-12, 9.00921402e-12, 7.43903672e-10,\n",
       "       1.99547483e-03, 1.99570248e-03, 3.86109172e-12, 3.86109172e-12,\n",
       "       9.00921402e-12, 7.45190703e-10, 2.00014321e-03, 0.00000000e+00,\n",
       "       3.86109172e-12, 3.86109172e-12, 9.00921402e-12, 7.43903672e-10,\n",
       "       2.00224249e-03, 2.00277762e-03, 3.86109172e-12, 3.86109172e-12,\n",
       "       1.02962446e-11, 7.43903672e-10, 2.00357631e-03, 2.00439727e-03,\n",
       "       3.86109172e-12, 3.86109172e-12, 9.00921402e-12, 7.43903672e-10,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[68569]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
